<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>KGAT-and-KGIN</title>
    <url>/2022/07/04/KGAT-and-KGIN/</url>
    <content><![CDATA[<h2 id="KGAT-Knowledge-Graph-Attention-Network-for-Recommendation"><a href="#KGAT-Knowledge-Graph-Attention-Network-for-Recommendation" class="headerlink" title="KGAT: Knowledge Graph Attention Network for Recommendation"></a>KGAT: Knowledge Graph Attention Network for Recommendation</h2><br/>

<h3 id="知识图谱增强推荐的介绍"><a href="#知识图谱增强推荐的介绍" class="headerlink" title="知识图谱增强推荐的介绍:"></a>知识图谱增强推荐的介绍:</h3><img src="9300fbb2eed78f16d802401cbc880b23.png" alt="截图" style="zoom:50%;" />

<p><strong>如图所示，我们一般在传统推荐系统(协同过滤)中拥有交互信息(user–item),但是不可避免会遇到冷启动以及数据稀疏问题，所以这时就要采用额外的辅助信息(side infomation)来帮助学习，知识图谱就作为其中一种，来辅助学习embedding。知识图谱通常由(h,r,t)三元组构成，其中h,t为实体，r为relation，如上图的(Titanic,acted,Leonardo),一般知识图谱推荐中不太会有社交网络的信息(获取不到friend)</strong></p>
<p><strong>GCN之前常用基于embedding的方法和基于元路径的方法，其中基于embedding的方法基本采用TransE等知识图谱embedding学习的方法来学得item的embedding作为先验输入到协同过滤(Collaborative Filtering)模型中去:(TransE模型大致如下思想)，就是使得学得得embedding满足，h + r = t</strong></p>
<img src="2373f21c1b9d62412ce22ef308dd5e0d.png" alt="截图" style="zoom:50%;" />

<p><strong>总结:学到了KG的语义信息</strong>    </p>
<p><strong>而基于路径得思想就是，假设存在 user 和 item 之间存在 K 个路径，针对其中的路径 p，学习到其向量表示为</strong> $\mathbf h_{\mathbf p}$** ，最终的路径信息如下，其中 g 可能是 max-pooling 或者是加权的 sum-pooling：**</p>
<img src="bb4beac4f97439026731ca9b5d8235bd.png" alt="截图" style="zoom:50%;" />

<p><strong>总结:学到了KG的联通信息</strong></p>
<p><strong>混合的方法基本就基于GCN的embedding传播思想,本文(KGAT)就是代表</strong></p>
<h3 id="本文主要思想概括"><a href="#本文主要思想概括" class="headerlink" title="本文主要思想概括:"></a>本文主要思想概括:</h3><p><strong>将User-Item交互矩阵变成(user,interaction,item),这种类似知识图谱的结构，其中user和item作为实体，interaction为新引入的relation 向量，这样的话，交互矩阵就可以和知识图谱成为一个整体的矩阵，最后在使用GAT的方式来聚合embedding,注意:本文使用KGE(TransR )和Recommendation任务迭代训练</strong></p>
<h3 id="collaborative-knowledge-graph-CKG-构造"><a href="#collaborative-knowledge-graph-CKG-构造" class="headerlink" title="collaborative knowledge graph (CKG)构造:"></a>collaborative knowledge graph (CKG)构造:</h3><img src="e198e24cc42aed31f80ebe834c3cb8e9.png" alt="截图" style="zoom:50%;" />

<p><strong>如图和上述可知:构图方式就是将交互矩阵添加交互关系形成KG中的三元组</strong></p>
<h3 id="KGE学习"><a href="#KGE学习" class="headerlink" title="KGE学习:"></a>KGE学习:</h3><img src="62b22e16a7ba456f3505f607ad46a325.png" alt="截图" style="zoom:70%;" />

<img src="5c8900d82ff0049c55115f5816bd197f.png" alt="截图" style="zoom:50%;" />

<h3 id="GAT聚合"><a href="#GAT聚合" class="headerlink" title="GAT聚合:"></a>GAT聚合:</h3><img src="2633d629c9d85faaab6586eedfd09058.png" alt="截图" style="zoom:70%;" />

<img src="c6c8077a4e20483e75071816121a4897.png" alt="截图" style="zoom:50%;" />

<p><strong>常见的attention聚合三步骤的范式,注意在计算attrntion系数时将</strong>$\mathbf W_{\mathbf r}$ <strong>乘以</strong> $\mathbf e_{\mathbf t}、\mathbf e_{\mathbf r}$<strong>是为了将emedding投入到relation空间，这里relation仅仅用作计算attention系数，要和后面一篇文章做区分。最后把邻居embedding和本身的embedding合并:文章给了三种，图中画的是Bi-Interaction</strong></p>
<img src="e81cd00a3b4d8431bd4d0718d4a4571f.png" alt="截图" style="zoom:50%;" />

<h3 id="模型训练："><a href="#模型训练：" class="headerlink" title="模型训练："></a>模型训练：</h3><img src="1c9d889ad7d1125d0b348875eac1a36c.png" alt="截图" style="zoom:70%;" />

<img src="57225f066d352f43d776fc63545e7d83.png" alt="截图" style="zoom:50%;" />

<img src="b91abc01a441bb8679c42716cd2b4f45.png" alt="截图" style="zoom:50%;" />

<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果:"></a>实验结果:</h3><img src="4d6a8bd5d4697ce1f6c0dbdacd61bd9a.png" alt="截图" style="zoom:50%;" />

<h2 id="Learning-Intents-behind-Interactions-with-Knowledge-Graph-for-Recommendation-KGIN"><a href="#Learning-Intents-behind-Interactions-with-Knowledge-Graph-for-Recommendation-KGIN" class="headerlink" title="Learning Intents behind Interactions with Knowledge Graph for Recommendation(KGIN)"></a>Learning Intents behind Interactions with Knowledge Graph for Recommendation(KGIN)</h2><h3 id="本文主要思想概括-1"><a href="#本文主要思想概括-1" class="headerlink" title="本文主要思想概括:"></a>本文主要思想概括:</h3><p><strong>这篇文章和上一篇主体差不多(毕竟是一个组出的文章),就是在构造CKG和聚合时有点区别.1.本文在勾走CKG时考虑到用户的多兴趣，将User-Item改成(User,p1,Item),(User,p2,Item)等其中(p1,p2是兴趣向量由KG中的relation线性组合而成).2.在聚合时将relation信息融入进去，而不是上文中realtion仅仅用来计算attention系数，具体就是聚合时将relation和实体做哈达玛积.3.最后得到最终embedding是sum而不是concat,没有采用KGE</strong></p>
<h3 id="collaborative-knowledge-graph-CKG-构造-1"><a href="#collaborative-knowledge-graph-CKG-构造-1" class="headerlink" title="collaborative knowledge graph (CKG)构造:"></a>collaborative knowledge graph (CKG)构造:</h3><p><strong>对于每一对交互历史(u,i)，在引入intent之后，都会变成(u,p1,i),(u,p2,i),(u,p3,i),(u,p4,i)，假设有4个意图embedding</strong></p>
<img src="9e6a6abdcbf906f783eb4ab0abd19836.png" alt="截图" style="zoom:50%;" />

<h3 id="兴趣建模"><a href="#兴趣建模" class="headerlink" title="兴趣建模:"></a>兴趣建模:</h3><img src="fa6bdb1cfc05ed17b9005455c492b3fb.png" alt="截图" style="zoom:50%;" />

<p><strong>这里作者仅采用随机可训练参数</strong>$\mathbf w_{\mathbf {rp}}$，<strong>为了使各个兴趣独立，采用如下方式:</strong></p>
<img src="c9c518945d78cbd6642936600b29d47d.png" alt="截图" style="zoom:50%;" />

<p><strong>思想:最小化兴趣直接的相似度–&gt;最小化兴趣间的联合概率–&gt;最小化兴趣间的互信息，或者直接最小化相关系数:</strong></p>
<img src="483d16bc7ae4b8869a65125f4b174ca3.png" alt="截图" style="zoom:50%;" />

<h3 id="Relational-Path-aware-Aggregation"><a href="#Relational-Path-aware-Aggregation" class="headerlink" title="Relational Path-aware Aggregation:"></a>Relational Path-aware Aggregation:</h3><img src="227af9bfe5f0cebee130ec154c53c7d6.png" alt="截图" style="zoom:70%;" />

<img src="465a2d77e8c9751a6bb1f4c6859af613.png" alt="截图" style="zoom:50%;" />

<p><strong>这里和上一篇有点不同，在于在聚合时将relation和实体哈达玛积，就是relation不仅仅用来计算attention系数还要融入聚合的embedding中,主要这里作者对user和item采用了不同的聚合方式.</strong></p>
<img src="6378067d5a3facdf14aa8ee93808bdf8.png" alt="截图" style="zoom:70%;" />

<img src="881bdce3ba3904ba1239ef6483504d35.png" alt="截图" style="zoom:50%;" />

<h3 id="模型训练：-1"><a href="#模型训练：-1" class="headerlink" title="模型训练："></a>模型训练：</h3><img src="690474494baa75623b5c2f720669c4f7.png" alt="截图" style="zoom:70%;" />

<img src="ff7a59221b2ff866c376904fccc4fc61.png" alt="截图" style="zoom:50%;" />

<p><strong>这里采用sum 来结合每层的embedding，且没有用KGE(相对与上文)</strong></p>
<h3 id="实验结果："><a href="#实验结果：" class="headerlink" title="实验结果："></a>实验结果：</h3><img src="a3828fd65342b74c8a318106ce5c83d9.png" alt="截图" style="zoom:50%;" />

<p><strong>注意这里KGAT的结果才是正确的，上一篇论文(KGAT)中，作者使用的NDCG计算有误，详情请看:</strong> <a href="https://github.com/huangtinglin/Knowledge_Graph_based_Intent_Network/issues/18">Issues</a></p>
]]></content>
      <tags>
        <tag>Knowledge</tag>
        <tag>Recommendation</tag>
      </tags>
  </entry>
  <entry>
    <title>SequencePrediction</title>
    <url>/2022/02/27/SequencePrediction/</url>
    <content><![CDATA[<p><a href="https://github.com/SunYuMs/Homework/">https://github.com/SunYuMs/Homework/</a><br><br/></p>
<h3 id="1-数据预处理"><a href="#1-数据预处理" class="headerlink" title="1.数据预处理"></a>1.数据预处理</h3><h4 id="a-为什么需要验证集？"><a href="#a-为什么需要验证集？" class="headerlink" title="(a) 为什么需要验证集？"></a>(a) 为什么需要验证集？</h4><p>验证集的作用在于模拟测试集，而测试集的最大特点就是未知，即在训练过程中是见不到的。正因为验证集和测试集在训练过程中都是未知的，我们才可以说，如果你的超参数适用于验证集，那么它们也大概会适用于测试集。如果你不分开验证集和测试集，那么我们调出的超参数就是适用于训练集的，但因为训练集和测试集不具有未知这个共同点，所以训练集上的好性能不一定能泛化到测试集上去，这就导致了过拟合。使得模型适合训练集而不适合测试集。</p>
<h4 id="b-应该如何选取验证集，验证集和测试集应该有什么联系"><a href="#b-应该如何选取验证集，验证集和测试集应该有什么联系" class="headerlink" title="(b) 应该如何选取验证集，验证集和测试集应该有什么联系?"></a>(b) 应该如何选取验证集，验证集和测试集应该有什么联系?</h4><p>通常可以在训练数据中中按照4:1或5:1等比例来划分训练集和验证集。因为超参数无法在训练集上进行训练,因此我们单独设立了一个验证集,用于选择(人工训练)最优的超参数.因为验证集是用于选择超参数的,因此验证集和训练集是独立不重叠的。而测试集是用于在完成神经网络训练后,为了客观评价模型在其未见过的数据上的性能,因此测试与验证集和训练集之间也是独立不重叠的,而且测试集不能提出对参数或者超参数的修改意见,只能作为评价网络性能的一个指标。</p>
<h4 id="c-为什么要在切分数据后再划分训练和验证集？直接在原始的时间序列中，划分几条作为验证集会出现什么问题？"><a href="#c-为什么要在切分数据后再划分训练和验证集？直接在原始的时间序列中，划分几条作为验证集会出现什么问题？" class="headerlink" title="(c) 为什么要在切分数据后再划分训练和验证集？直接在原始的时间序列中，划分几条作为验证集会出现什么问题？"></a>(c) 为什么要在切分数据后再划分训练和验证集？直接在原始的时间序列中，划分几条作为验证集会出现什么问题？</h4><p>对于时间序列预测这种任务，如果你的验证集中与训练集中时间上出现重叠，模型会在训练时记忆你训练集中出现的重叠数据，。例如，告诉你5日到10日的数据，让你预测第11日数据（验证阶段）；同时，给你11日到16日的数据，让你预测第17日的数据（训练阶段）。这11日的价格模型已经遇见过了，影响了神经单元权重，自然在验证时无法做到客观。而直接在原始的时间序列中，划分几条作为验证集，可能会导致上述情况发生，所以需要先切分数据再划分训练和验证集，所以一定要选择老数据进行training,新数据进行validation。</p>
<h4 id="d-数据参与训练的时候打乱顺序-shuffle-输入模型，会有什么好处，什么坏处？"><a href="#d-数据参与训练的时候打乱顺序-shuffle-输入模型，会有什么好处，什么坏处？" class="headerlink" title="(d) 数据参与训练的时候打乱顺序(shuffle)输入模型，会有什么好处，什么坏处？"></a>(d) 数据参与训练的时候打乱顺序(shuffle)输入模型，会有什么好处，什么坏处？</h4><p>将训练模型的数据集进行打乱的操作。原始的数据，在样本均衡的情况下可能是按照某种顺序进行排列，如前半部分为某一类别的数据，后半部分为另一类别的数据。但经过打乱之后数据的排列就会拥有一定的随机性，在顺序读取的时候下一次得到的样本为任何一类型的数据的可能性相同。</p>
<ul>
<li>Shuffle可以防止训练过程中的模型抖动，有利于模型的健壮性</li>
</ul>
<p>假设训练数据分为两类，在未经过Shuffle的训练时，首先模型的参数会去拟合第一类数据，当大量的连续数据（第一类）输入训练时，会造成模型在第一类数据上的过拟合。当第一类数据学习结束后模型又开始对大量的第二类数据进行学习，这样会使模型尽力去逼近第二类数据，造成新的过拟合现象。这样反复的训练模型会在两种过拟合之间徘徊，造成模型的抖动，也不利于模型的收敛和训练的快速收敛</p>
<ul>
<li>Shuffle可以防止过拟合，并且使得模型学到更加正确的特征</li>
</ul>
<p>神经网络的学习能力很强，如果数据未经过打乱，则模型反复依次序学习数据的特征，很快就会达到过拟合状态，并且有可能学会的只是数据的次序特征。模型的缺乏泛化能力。</p>
<ul>
<li>为使得训练集，验证集，测试集中数据分布类似  但是模型本身就为序列模型，则数据集的次序特征为数据的主要特征，并且模型需要学到这种次序规律时，则不可以使用Shuffle。否则会将数据集中的特征破坏。</li>
</ul>
<h3 id="2-模型建立"><a href="#2-模型建立" class="headerlink" title="2.模型建立"></a>2.模型建立</h3><h4 id="a-输入层和输出层应该是什么层-为什么"><a href="#a-输入层和输出层应该是什么层-为什么" class="headerlink" title="(a) 输入层和输出层应该是什么层?为什么?"></a>(a) 输入层和输出层应该是什么层?为什么?</h4><p>输入层：输入变量，有时称为可见层。输出层：生成输出变量的节点层。</p>
<h4 id="b-隐藏层应该有多少层-过多或过少分别会带来什么问题"><a href="#b-隐藏层应该有多少层-过多或过少分别会带来什么问题" class="headerlink" title="(b) 隐藏层应该有多少层?过多或过少分别会带来什么问题?"></a>(b) 隐藏层应该有多少层?过多或过少分别会带来什么问题?</h4><p>本次实验隐藏层用了两层，增加隐层数可以降低网络误差，提高精度，但也使网络复杂化，从而增加了网络的训练时间和出现“过拟合”的倾向，反之隐藏层过少会无法学习数据的特征，导致模型效果不佳。</p>
<h4 id="c-除了全连接网络-MLP-，还可以使用什么网络模块来解决这个问题？"><a href="#c-除了全连接网络-MLP-，还可以使用什么网络模块来解决这个问题？" class="headerlink" title="(c) 除了全连接网络(MLP)，还可以使用什么网络模块来解决这个问题？"></a>(c) 除了全连接网络(MLP)，还可以使用什么网络模块来解决这个问题？</h4><p>除了MLP还可以使用LSTM等时序网络结构来解决这个问题</p>
<h4 id="d-【代码题】请用至少一种其它网络模块来搭建网络，并和-MLP-网络对比优缺点。"><a href="#d-【代码题】请用至少一种其它网络模块来搭建网络，并和-MLP-网络对比优缺点。" class="headerlink" title="(d)【代码题】请用至少一种其它网络模块来搭建网络，并和 MLP 网络对比优缺点。"></a>(d)【代码题】请用至少一种其它网络模块来搭建网络，并和 MLP 网络对比优缺点。</h4><h5 id="i-注意-本题不要求手写网络的同学进行实践"><a href="#i-注意-本题不要求手写网络的同学进行实践" class="headerlink" title="i. 注意:本题不要求手写网络的同学进行实践"></a>i. 注意:本题不要求手写网络的同学进行实践</h5><h5 id="ii-如果本身没有选择-MLP-来搭建模型，在本题中，则搭建-MLP-模型来完成预测任务"><a href="#ii-如果本身没有选择-MLP-来搭建模型，在本题中，则搭建-MLP-模型来完成预测任务" class="headerlink" title="ii. 如果本身没有选择 MLP 来搭建模型，在本题中，则搭建 MLP 模型来完成预测任务"></a>ii. 如果本身没有选择 MLP 来搭建模型，在本题中，则搭建 MLP 模型来完成预测任务</h5><h5 id="MLP："><a href="#MLP：" class="headerlink" title="MLP："></a>MLP：</h5><p>随着神经网络层数的加深，优化函数越来越容易陷入局部最优解。利用有限数据训练的深层网络，性能还不如较浅层网络。而且随着网络层数增加，“梯度消失”现象更加严重。</p>
<h5 id="LSTM："><a href="#LSTM：" class="headerlink" title="LSTM："></a>LSTM：</h5><p>MLP并不完全适用于学习时间序列，且效果也不一定好。对时间序列敏感的问题而言，RNN(如LSTM)通常会比较合适。RNN用于序列数据，并且有了一定的记忆效应；但是LSTM计算费时。每一个LSTM的cell里面都意味着有4个全连接层(MLP),如果LSTM的时间跨度很大，并且网络又很深，这个计算量会很大，很耗时。</p>
<br/>

<h3 id="3-损失函数"><a href="#3-损失函数" class="headerlink" title="3.损失函数"></a>3.损失函数</h3><h4 id="a-mean-absolute-error-MAE-和-mean-squared-error-MSE-做损失函数有区别吗？请简单分析一下。"><a href="#a-mean-absolute-error-MAE-和-mean-squared-error-MSE-做损失函数有区别吗？请简单分析一下。" class="headerlink" title="(a) mean absolute error(MAE)和 mean squared error(MSE)做损失函数有区别吗？请简单分析一下。"></a>(a) mean absolute error(MAE)和 mean squared error(MSE)做损失函数有区别吗？请简单分析一下。</h4><p>MSE可以更快收敛：MSE的损失梯度为$-y_i$，MAE的损失梯度为+-1，也就是说MSE的梯度大小会随着误差大小变化，而MAE的梯度则一直保持为1(即使是在绝对误差很小的情况下)。MAE损失对于绝对误差是线性关系，MSE是平方关系。当误差非常大的时候，MSE损失会远远大于MAE，导致对模型的影响比较大。</p>
<h4 id="b-【代码题】请分别用这两种损失函数进行训练，对比模型的指标表现，并分析原因。"><a href="#b-【代码题】请分别用这两种损失函数进行训练，对比模型的指标表现，并分析原因。" class="headerlink" title="(b)【代码题】请分别用这两种损失函数进行训练，对比模型的指标表现，并分析原因。"></a>(b)【代码题】请分别用这两种损失函数进行训练，对比模型的指标表现，并分析原因。</h4><p>MSE损失函数效果较MAE的好，数聚集中被污染的数据较少，所以在梯度下降方面MSE的效果由于MAE。而MAE更新的梯度始终相同，也就是说，即使对于很小的损失值，梯度也很大。这样不利于模型的学习。</p>
<h4 id="c-如果让你改进损失函数，你会如何改进-指出当前损失函数存在的问题，-并提出一个解决方案。无需具体证明"><a href="#c-如果让你改进损失函数，你会如何改进-指出当前损失函数存在的问题，-并提出一个解决方案。无需具体证明" class="headerlink" title="(c) 如果让你改进损失函数，你会如何改进?(指出当前损失函数存在的问题， 并提出一个解决方案。无需具体证明)"></a>(c) 如果让你改进损失函数，你会如何改进?(指出当前损失函数存在的问题， 并提出一个解决方案。无需具体证明)</h4><p>MSE在损失接近与0时，梯度比较小，所以可以适当提高学习率。</p>
<h3 id="4-优化方法"><a href="#4-优化方法" class="headerlink" title="4.优化方法"></a>4.优化方法</h3><h4 id="a-你选择了什么优化方法-例如-SGD，Adam-等-？为什么？"><a href="#a-你选择了什么优化方法-例如-SGD，Adam-等-？为什么？" class="headerlink" title="(a) 你选择了什么优化方法(例如 SGD，Adam 等)？为什么？"></a>(a) 你选择了什么优化方法(例如 SGD，Adam 等)？为什么？</h4><p>我采用的是SGD，SGD简单且有效</p>
<h4 id="b-在-SGD-上增加动量会改变模型性能吗？为什么"><a href="#b-在-SGD-上增加动量会改变模型性能吗？为什么" class="headerlink" title="(b) 在 SGD 上增加动量会改变模型性能吗？为什么?"></a>(b) 在 SGD 上增加动量会改变模型性能吗？为什么?</h4><p>在本次实验上，我通过增加动量模型的性能并无提升，可能和参数$\beta$的选取有关，我分别尝试了0.9和0.1，发现在0.9时效果比SGD较差，0.1时模型效果差不多。</p>
<h3 id="5-训练"><a href="#5-训练" class="headerlink" title="5.训练"></a>5.训练</h3><h4 id="a-在上述所有尝试过的模型中，请分别汇报训练集和验证集的损失"><a href="#a-在上述所有尝试过的模型中，请分别汇报训练集和验证集的损失" class="headerlink" title="(a) 在上述所有尝试过的模型中，请分别汇报训练集和验证集的损失"></a>(a) 在上述所有尝试过的模型中，请分别汇报训练集和验证集的损失</h4><table>
<thead>
<tr>
<th align="center">模型名称</th>
<th align="center">训练集loss</th>
<th align="center">验证集loss</th>
</tr>
</thead>
<tbody><tr>
<td align="center">MSE+MLP+SGD</td>
<td align="center">0.008243</td>
<td align="center">0.008250</td>
</tr>
<tr>
<td align="center">MAE+MLP+SGD</td>
<td align="center">0.061002</td>
<td align="center">0.056368</td>
</tr>
<tr>
<td align="center">MSE+MLP+SGD(动量 )$\beta =0.1$</td>
<td align="center">0.008319</td>
<td align="center">0.008316</td>
</tr>
<tr>
<td align="center">MAE+MLP+SGD(动量 )$\beta =0.1$</td>
<td align="center">0.061184</td>
<td align="center">0.056679</td>
</tr>
<tr>
<td align="center">MSE+LSTM +Adam</td>
<td align="center">0.022204</td>
<td align="center">/</td>
</tr>
</tbody></table>
<h4 id="b-在上述所有尝试过的模型中，请分别汇报训练集和验证集的-sMAPE"><a href="#b-在上述所有尝试过的模型中，请分别汇报训练集和验证集的-sMAPE" class="headerlink" title="(b) 在上述所有尝试过的模型中，请分别汇报训练集和验证集的 sMAPE"></a>(b) 在上述所有尝试过的模型中，请分别汇报训练集和验证集的 sMAPE</h4><table>
<thead>
<tr>
<th align="center">模型名称</th>
<th align="center">训练集sMAPE</th>
<th align="center">验证集sMAPE</th>
</tr>
</thead>
<tbody><tr>
<td align="center">MSE+MLP+SGD</td>
<td align="center">27.11</td>
<td align="center">26.20</td>
</tr>
<tr>
<td align="center">MAE+MLP+SGD</td>
<td align="center">27.83</td>
<td align="center">24.78</td>
</tr>
<tr>
<td align="center">MSE+MLP+SGD(动量 )$\beta =0.1$</td>
<td align="center">27.22</td>
<td align="center">26.28</td>
</tr>
<tr>
<td align="center">MAE+MLP+SGD(动量 )$\beta =0.1$</td>
<td align="center">27.93</td>
<td align="center">24.89</td>
</tr>
<tr>
<td align="center">MSE+LSTM +Adam</td>
<td align="center">26.102</td>
<td align="center">/</td>
</tr>
</tbody></table>
<br/>

<h3 id="6-测试"><a href="#6-测试" class="headerlink" title="6.测试"></a>6.测试</h3><h4 id="a-在上述的尝试中，请汇报测试集上的最优损失，请标明模型，损失函数和优化方法"><a href="#a-在上述的尝试中，请汇报测试集上的最优损失，请标明模型，损失函数和优化方法" class="headerlink" title="(a) 在上述的尝试中，请汇报测试集上的最优损失，请标明模型，损失函数和优化方法"></a>(a) 在上述的尝试中，请汇报测试集上的最优损失，请标明模型，损失函数和优化方法</h4><table>
<thead>
<tr>
<th align="center">模型名称</th>
<th align="center">测试集损失</th>
</tr>
</thead>
<tbody><tr>
<td align="center">MLP+MSE+SGD</td>
<td align="center">0.008243</td>
</tr>
</tbody></table>
<h4 id="b-在上述的尝试中，请汇报测试集上的最优-sMAPE，请标明模型，损失函数和优化方法"><a href="#b-在上述的尝试中，请汇报测试集上的最优-sMAPE，请标明模型，损失函数和优化方法" class="headerlink" title="(b) 在上述的尝试中，请汇报测试集上的最优 sMAPE，请标明模型，损失函数和优化方法"></a>(b) 在上述的尝试中，请汇报测试集上的最优 sMAPE，请标明模型，损失函数和优化方法</h4><br/>

<table>
<thead>
<tr>
<th align="center">模型名称</th>
<th align="center">测试集sMAPE</th>
</tr>
</thead>
<tbody><tr>
<td align="center">LSTM+MSE+Adam</td>
<td align="center">26.385</td>
</tr>
</tbody></table>
<h3 id="7-不同训练长度的测试结果对比"><a href="#7-不同训练长度的测试结果对比" class="headerlink" title="7.不同训练长度的测试结果对比"></a>7.不同训练长度的测试结果对比</h3><h4 id="a-【代码题】请至少尝试三种输入长度，对网络进行训练和测试。"><a href="#a-【代码题】请至少尝试三种输入长度，对网络进行训练和测试。" class="headerlink" title="(a)【代码题】请至少尝试三种输入长度，对网络进行训练和测试。"></a>(a)【代码题】请至少尝试三种输入长度，对网络进行训练和测试。</h4><br/>

<table>
<thead>
<tr>
<th align="center">输入长度</th>
<th align="center">测试集sMAPE</th>
</tr>
</thead>
<tbody><tr>
<td align="center">56</td>
<td align="center">27.28</td>
</tr>
<tr>
<td align="center">60</td>
<td align="center">27.25</td>
</tr>
<tr>
<td align="center">70</td>
<td align="center">29.48</td>
</tr>
</tbody></table>
<h4 id="b-你认为选择输入长度的依据应该是什么？最优的是哪一个输入长度？"><a href="#b-你认为选择输入长度的依据应该是什么？最优的是哪一个输入长度？" class="headerlink" title="(b) 你认为选择输入长度的依据应该是什么？最优的是哪一个输入长度？"></a>(b) 你认为选择输入长度的依据应该是什么？最优的是哪一个输入长度？</h4><p>我认为输入长度应该大于等于输出长度，最优长度是60</p>
<h4 id="c-输入长度的选择可以自动化吗？请给出理由。"><a href="#c-输入长度的选择可以自动化吗？请给出理由。" class="headerlink" title="(c) 输入长度的选择可以自动化吗？请给出理由。"></a>(c) 输入长度的选择可以自动化吗？请给出理由。</h4><p>输入长度的选择应该可以自动化，输入长度其实也是一个超参数，现有的工具已经可以对超参数的选取起到很大的帮助。</p>
<h4 id="d-总结汇报最优的训练-验证-测试集损失和-sMAPE，请标明输入长度，模型，损失函数和优化方法"><a href="#d-总结汇报最优的训练-验证-测试集损失和-sMAPE，请标明输入长度，模型，损失函数和优化方法" class="headerlink" title="(d) 总结汇报最优的训练/验证/测试集损失和 sMAPE，请标明输入长度，模型，损失函数和优化方法"></a>(d) 总结汇报最优的训练/验证/测试集损失和 sMAPE，请标明输入长度，模型，损失函数和优化方法</h4><table>
<thead>
<tr>
<th align="center">模型名</th>
<th align="center">训练集loss</th>
<th align="center">训练集sMAPE</th>
<th align="center">验证集loss</th>
<th align="center">验证集sMAPE</th>
<th align="center">测试集损失</th>
<th align="center">测试集sMAPE</th>
</tr>
</thead>
<tbody><tr>
<td align="center">60+MLP+MSE+SGD</td>
<td align="center">0.008243</td>
<td align="center">27.11</td>
<td align="center">0.008250</td>
<td align="center">26.20</td>
<td align="center">0.029185</td>
<td align="center">27.26</td>
</tr>
</tbody></table>
]]></content>
      <tags>
        <tag>homework</tag>
      </tags>
  </entry>
  <entry>
    <title>Minst</title>
    <url>/2022/02/27/MNIST/</url>
    <content><![CDATA[<h2 id="作业一：手写数字分类"><a href="#作业一：手写数字分类" class="headerlink" title="作业一：手写数字分类"></a>作业一：手写数字分类</h2><p><strong>我通过对比不同参数的初始化方法（标准正太分布、kaiming、Glorot）发现kaming初始化方法效果较好。通过对比不同的损失函数（交叉熵损失函数和MSE）由于我最后一层采用的是softmax层所以交叉熵损失函数效果明显好于MSE，采用MSE时效果极其差劣，后来我将最后一层改为sigmod层用MSE实验后发现效果有着显著提升但不及softmax+交叉熵，所以可以得出结论再多分类任务中softmax和交叉熵损失比较搭配。</strong></p>
<p><strong>我简单尝试了不同的学习率调整方案(固定学习率、指数下降、学习率预热)，或许是我之前就已经调整过学习率的原因，所以在我的模型中固定学习率的效果较好（0.3）。在对比不同正则化实验中，我开始将正则化参数调的较大，发现模型效果较差，认为手写数字识别这种简单模型或许不太需要正则化来约束参数，其中L2正则化效果优于L1正则化，具体的实验结果如下：</strong></p>
<p><strong>最后我采用的模型是（kaiming初始化+交叉熵损失函数+0.3固定学习率+无正则化）最优准确率98.24%</strong></p>
<p><a href="https://github.com/SunYuMs/Homework/">https://github.com/SunYuMs/Homework/</a></p>
<br/>

<h3 id="（1）对比不同的参数初始化方法"><a href="#（1）对比不同的参数初始化方法" class="headerlink" title="（1）对比不同的参数初始化方法"></a>（1）对比不同的参数初始化方法</h3><br/>

<table>
<thead>
<tr>
<th align="center">初始化方法</th>
<th align="center">测试集准确率%</th>
</tr>
</thead>
<tbody><tr>
<td align="center">标准正太分布初始化（Baseline）</td>
<td align="center">96.15</td>
</tr>
<tr>
<td align="center">kaiming初始化</td>
<td align="center">98.24</td>
</tr>
<tr>
<td align="center">Glorot初始化</td>
<td align="center">98.20</td>
</tr>
</tbody></table>
<img src="4c2f651ac53336420097632a284c7043.png" alt="截图" style="zoom:70%;" />

<h3 id="（2）对比不同的损失函数"><a href="#（2）对比不同的损失函数" class="headerlink" title="（2）对比不同的损失函数"></a>（2）对比不同的损失函数</h3><table>
<thead>
<tr>
<th align="center">损失函数</th>
<th align="center">测试集准确率%</th>
</tr>
</thead>
<tbody><tr>
<td align="center">交叉熵损失函数（Baseline）</td>
<td align="center">96.15</td>
</tr>
<tr>
<td align="center">MS</td>
<td align="center">65.40</td>
</tr>
</tbody></table>
<img src="1fa54bd0960f4a2bef7d57687cf9e06d.png" alt="截图" style="zoom:70%;" />

<h3 id="（3）对比不同的学习率调整方法"><a href="#（3）对比不同的学习率调整方法" class="headerlink" title="（3）对比不同的学习率调整方法"></a>（3）对比不同的学习率调整方法</h3><table>
<thead>
<tr>
<th align="center">学习率调整方法</th>
<th align="center">测试集准确率%</th>
</tr>
</thead>
<tbody><tr>
<td align="center">固定（Baseline）</td>
<td align="center">96.15</td>
</tr>
<tr>
<td align="center">学习率预热</td>
<td align="center">95.16</td>
</tr>
<tr>
<td align="center">指数下降</td>
<td align="center">96.08</td>
</tr>
</tbody></table>
<img src="a7ad51c113701c1f6288b44ed5ce6850.png" alt="截图" style="zoom:70%;" />

<h3 id="（4）对比不同的正则化方法"><a href="#（4）对比不同的正则化方法" class="headerlink" title="（4）对比不同的正则化方法"></a>（4）对比不同的正则化方法</h3><table>
<thead>
<tr>
<th align="center">正则化方法</th>
<th align="center">测试集准确率%</th>
</tr>
</thead>
<tbody><tr>
<td align="center">无正则（Baseline）</td>
<td align="center">96.15</td>
</tr>
<tr>
<td align="center">L1</td>
<td align="center">95.94</td>
</tr>
<tr>
<td align="center">L2</td>
<td align="center">97.01</td>
</tr>
</tbody></table>
<img src="10d296dc3d938cd1db9c63762c0b6be7.png" alt="截图" style="zoom:70%;" />
]]></content>
  </entry>
</search>
